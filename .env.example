# API Keys
REPLICATE_API_TOKEN=your_replicate_api_token_here
OPENAI_API_KEY=your_openai_api_key_here

# LLM Configuration
# Supported models (examples):
# - OpenAI: gpt-4, gpt-4-turbo, gpt-4o, gpt-3.5-turbo
# - Anthropic: claude-3-opus-20240229, claude-3-sonnet-20240229
# - xAI: xai/grok-beta
# - Groq: groq/llama3-8b-8192, groq/mixtral-8x7b-32768
# - Mistral: mistral/mistral-7b-instruct
# - Together AI: together_ai/meta-llama/Llama-2-7b-chat-hf
# Note: Use standard model names. Special versions like gpt-4-1-2025-04-14
# will be automatically mapped to gpt-4 for compatibility.
LLM_MODEL=gpt-4

# Replicate Models (comma-separated list of owner/model:version)
# Example: REPLICATE_MODELS=stability-ai/sdxl:db21e45d3f7023abc2a46ee38a23973f6dce16bb082a930b0c49861f96d1e5bf,another/model:version
REPLICATE_MODELS=black-forest-labs/flux-1.1-pro-ultra,black-forest-labs/flux-1.1-pro,black-forest-labs/flux-pro

# Flask Configuration
FLASK_ENV=production
FLASK_APP=app.py
SECRET_KEY=your_secret_key_here  # Generate a secure random key for production

# Server Configuration
HOST=0.0.0.0
PORT=5000

# Rate Limiting
RATELIMIT_STORAGE_URL=memory://  # Use Redis in production
RATELIMIT_DEFAULT=30/hour
RATELIMIT_STRATEGY=fixed-window

# Logging
LOG_LEVEL=INFO
LOG_FILE=app.log

# Gunicorn configuration (optional, read by app.sh --production, defaults to 0.0.0.0:8000)
# GUNICORN_HOST=0.0.0.0
# GUNICORN_PORT=8000
